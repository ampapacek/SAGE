# Flask
SECRET_KEY=dev
MAX_CONTENT_LENGTH=52428800

# LLM base configuration
LLM_PROVIDER=custom1
LLM_API_KEY=your_api_key_here
LLM_API_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-5-mini
OPENAI_MODEL_OPTIONS=gpt-4o-mini,gpt-5-mini,gpt-4o,gpt-4.1,gpt-4.1-mini,o4-mini,o3-mini,gpt-5,gpt-5-nano

# LLM behavior
LLM_USE_JSON_MODE=1
# Max output tokens for Responses/Chat (higher = more cost, fewer truncations)
LLM_MAX_OUTPUT_TOKENS=1200
# HTTP timeout for LLM requests (seconds)
LLM_REQUEST_TIMEOUT=120

# LLM pricing reference (per 1M tokens):
# GPT-5: input 1.25, output 10.00
# GPT-5 mini: input 0.25, output 2.00
# GPT-4o mini: input 0.15, output 0.60
# o4-mini: input 1.10, output 4.40
# GPT-5 nano: input 0.05, output 0.40
LLM_PRICE_INPUT_PER_1K=0.00025
LLM_PRICE_OUTPUT_PER_1K=0.002
# Estimated tokens charged per image (provider-dependent)
LLM_IMAGE_TOKENS_PER_IMAGE=1000

# Custom provider 1 (OpenRouter example)
CUSTOM_LLM_PROVIDER_1_NAME=OpenRouter
CUSTOM_LLM_PROVIDER_1_API_KEY=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
CUSTOM_LLM_PROVIDER_1_API_BASE_URL=https://openrouter.ai/api/v1
CUSTOM_LLM_PROVIDER_1_DEFAULT_MODEL=openai/gpt-oss-120b:free
CUSTOM_LLM_PROVIDER_1_MODELS=openai/gpt-oss-120b:free

# Custom provider 2
CUSTOM_LLM_PROVIDER_2_NAME=Other 2
CUSTOM_LLM_PROVIDER_2_API_KEY=
CUSTOM_LLM_PROVIDER_2_API_BASE_URL=
CUSTOM_LLM_PROVIDER_2_DEFAULT_MODEL=
CUSTOM_LLM_PROVIDER_2_MODELS=

# Custom provider 3
CUSTOM_LLM_PROVIDER_3_NAME=Other 3
CUSTOM_LLM_PROVIDER_3_API_KEY=
CUSTOM_LLM_PROVIDER_3_API_BASE_URL=
CUSTOM_LLM_PROVIDER_3_DEFAULT_MODEL=
CUSTOM_LLM_PROVIDER_3_MODELS=

# Optional: Redis for RQ
REDIS_URL=redis://localhost:6379/0

# PDF rendering
PDF_DPI=400
PDF_TEXT_MIN_CHARS=80
PDF_TEXT_MIN_RATIO=0.9
